{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.models.rnn import rnn_cell\n",
    "from tensorflow.models.rnn import rnn\n",
    "\n",
    "#Defining some hyper-params\n",
    "n_hidden = 2       #this is the parameter for input_size in the basic LSTM cell\n",
    "input_size = 2      #n_hidden and input_size will be the same\n",
    "embedding_size = 300\n",
    "\n",
    "batch_size = 50\n",
    "sentence_length = 55\n",
    "num_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data.load as load\n",
    "from functools import reduce\n",
    "\n",
    "#train_set, valid_set, test_set, dic = load.atisfold(3)\n",
    "train_set, test_set, dic = load.atisfull()\n",
    "idx_pad = max(dic['words2idx'].values()) + 1\n",
    "dic['words2idx']['<PAD>'] = idx_pad\n",
    "\n",
    "idx2label = dict((v,k) for k,v in dic['labels2idx'].items())\n",
    "idx2word = dict((v,k) for k,v in dic['words2idx'].items())\n",
    "\n",
    "train_lex, train_ne, train_y = train_set\n",
    "#valid_lex, valid_ne, valid_y = valid_set\n",
    "test_lex,  test_ne,  test_y  = test_set\n",
    "\n",
    "vocsize = len(set(reduce(lambda x, y: list(x)+list(y),\n",
    "                         train_lex+test_lex))) + 1 # +1 for padding\n",
    "\n",
    "nclasses = len(set(reduce(lambda x, y: list(x)+list(y),\n",
    "                          train_y+test_y)))\n",
    "nsentences = len(train_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "max_sentence = max([len(s) for s in train_lex])\n",
    "print(max_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n",
      "572\n"
     ]
    }
   ],
   "source": [
    "print(vocsize)\n",
    "print(idx_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5871"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lex) + len(test_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padding(sentence, pad=-1, max_length=50):\n",
    "    length = len(sentence)\n",
    "    if len(sentence) < max_length:\n",
    "        sentence = np.append(sentence, [pad] * (max_length - length))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232 542 502 196 208  77  62  10  35  40  58 234 137  62  11 234 481 321\n",
      "  46  46  46  46  46  46  46  46  46  46  46  46  46  46  46  46  46  46\n",
      "  46  46  46  46  46  46  46  46  46  46  46  46  46  46]\n",
      "[126 126 126 126 126  48 126  35  99 126 126 126  78 126  14 126 126  12]\n"
     ]
    }
   ],
   "source": [
    "print(padding(train_lex[0], 46))\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "\"\"\"\n",
    "each batch is a sentence\n",
    "each batch is a 2D matrix\n",
    "* height: length of the sentence\n",
    "* width: the vocaburary size\n",
    "\"\"\"\n",
    "def gen_data(source, s_pad, Y, y_pad, max_length, vocsize, nclasses, n_batch=5):\n",
    "    l = n_batch\n",
    "    for i in range(len(source)):\n",
    "        if (i*l+l) >= len(source):\n",
    "            break\n",
    "        sentences = source[i*l:i*l+l]\n",
    "        X = []\n",
    "        for sentence in sentences:\n",
    "            sentence = padding(sentence, s_pad, max_length=max_length)\n",
    "            row = np.array([j for j in range(len(sentence))])\n",
    "            col = np.array([sentence[j] for j in range(len(sentence))])\n",
    "            data = np.array([1 for _ in range(len(sentence))])\n",
    "            matrix = csc_matrix((data, (row, col)), shape=(max_length, vocsize))\n",
    "            X.append(matrix)\n",
    "        \n",
    "        batch_answer = Y[i*l:i*l+l]\n",
    "        y = []\n",
    "        for answer_seq in batch_answer:\n",
    "            answer_seq = padding(answer_seq, y_pad, max_length=max_length)\n",
    "            row = np.array([j for j in range(len(sentence))])\n",
    "            col = np.array([answer_seq[j] for j in range(len(sentence))])\n",
    "            data = np.array([1 for _ in range(len(sentence))])\n",
    "            matrix = csc_matrix((data, (row, col)), shape=(max_length, nclasses))\n",
    "            y.append(matrix)            \n",
    "        \n",
    "        yield (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = gen_data(train_lex, idx_pad, train_y, 126, max_sentence, 573, nclasses, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Model Construction\n",
    "\n",
    "cell = rnn_cell.BasicLSTMCell(n_hidden)    #we use the basic LSTM cell provided in TensorFlow\n",
    "                                            #num units is the input-size for this cell\n",
    "\n",
    "#create placeholders for X and y\n",
    "\n",
    "inputs = [tf.placeholder(tf.float32,shape=[batch_size, input_size]) for _ in range(sentence_length)]\n",
    "result = tf.placeholder(tf.float32, shape=[batch_size, sentence_length, nclasses])\n",
    "\n",
    "outputs, states = rnn.rnn(cell, inputs, dtype=tf.float32)   #note that outputs is a list of seq_len\n",
    "                                                            #each element is a tensor of size [batch_size,num_units]\n",
    "\n",
    "outputs2 = outputs[-1]   #we actually only need the last output from the model, ie: last element of outputs\n",
    "\n",
    "\n",
    "#We actually want the output to be size [batch_size, 1]\n",
    "#So we will implement a linear layer to do this\n",
    "\n",
    "W_o = tf.Variable(tf.random_normal([2,1], stddev=0.01))     \n",
    "b_o = tf.Variable(tf.random_normal([1], stddev=0.01))\n",
    "\n",
    "outputs2 = outputs[-1]\n",
    "\n",
    "outputs3 = tf.matmul(outputs2,W_o) + b_o       \n",
    "\n",
    "cost = tf.reduce_mean(tf.pow(outputs3-result,2))    #compute the cost for this batch of data\n",
    "\n",
    "#compute updates to parameters in order to minimize cost\n",
    "\n",
    "#train_op = tf.train.GradientDescentOptimizer(0.008).minimize(cost)\n",
    "train_op = tf.train.RMSPropOptimizer(0.005, 0.2).minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Generate Validation Data\n",
    "tempX,y_val = gen_data(50,seq_len,batch_size)\n",
    "X_val = []\n",
    "for i in range(seq_len):\n",
    "    X_val.append(tempX[:,i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation cost: 1.1978884935379028, on Epoch 0\n",
      "Validation cost: 1.1830931901931763, on Epoch 1\n",
      "Validation cost: 1.1687648296356201, on Epoch 2\n",
      "Validation cost: 1.153106451034546, on Epoch 3\n",
      "Validation cost: 1.1375610828399658, on Epoch 4\n",
      "Validation cost: 1.1218794584274292, on Epoch 5\n",
      "Validation cost: 1.1052356958389282, on Epoch 6\n",
      "Validation cost: 1.0882318019866943, on Epoch 7\n",
      "Validation cost: 1.0709738731384277, on Epoch 8\n",
      "Validation cost: 1.0545097589492798, on Epoch 9\n",
      "Validation cost: 1.037086844444275, on Epoch 10\n",
      "Validation cost: 1.0197356939315796, on Epoch 11\n",
      "Validation cost: 1.0022794008255005, on Epoch 12\n",
      "Validation cost: 0.9850460886955261, on Epoch 13\n",
      "Validation cost: 0.9678436517715454, on Epoch 14\n",
      "Validation cost: 0.9506497979164124, on Epoch 15\n",
      "Validation cost: 0.9332269430160522, on Epoch 16\n",
      "Validation cost: 0.9158437252044678, on Epoch 17\n",
      "Validation cost: 0.8984217643737793, on Epoch 18\n",
      "Validation cost: 0.8811301589012146, on Epoch 19\n",
      "Validation cost: 0.8635833859443665, on Epoch 20\n",
      "Validation cost: 0.8461878895759583, on Epoch 21\n",
      "Validation cost: 0.8285347819328308, on Epoch 22\n",
      "Validation cost: 0.8107160925865173, on Epoch 23\n",
      "Validation cost: 0.7935569286346436, on Epoch 24\n",
      "Validation cost: 0.7763214111328125, on Epoch 25\n",
      "Validation cost: 0.7590198516845703, on Epoch 26\n",
      "Validation cost: 0.7412842512130737, on Epoch 27\n",
      "Validation cost: 0.7240901589393616, on Epoch 28\n",
      "Validation cost: 0.7069709300994873, on Epoch 29\n",
      "Validation cost: 0.6895491480827332, on Epoch 30\n",
      "Validation cost: 0.6728519797325134, on Epoch 31\n",
      "Validation cost: 0.6556618809700012, on Epoch 32\n",
      "Validation cost: 0.6391313672065735, on Epoch 33\n",
      "Validation cost: 0.6219456791877747, on Epoch 34\n",
      "Validation cost: 0.6053982377052307, on Epoch 35\n",
      "Validation cost: 0.5893157720565796, on Epoch 36\n",
      "Validation cost: 0.5736992955207825, on Epoch 37\n",
      "Validation cost: 0.5572099089622498, on Epoch 38\n",
      "Validation cost: 0.5415831804275513, on Epoch 39\n",
      "Validation cost: 0.5257437825202942, on Epoch 40\n",
      "Validation cost: 0.5106101632118225, on Epoch 41\n",
      "Validation cost: 0.495303213596344, on Epoch 42\n",
      "Validation cost: 0.48141640424728394, on Epoch 43\n",
      "Validation cost: 0.4674040675163269, on Epoch 44\n",
      "Validation cost: 0.4544624090194702, on Epoch 45\n",
      "Validation cost: 0.4402019679546356, on Epoch 46\n",
      "Validation cost: 0.42638564109802246, on Epoch 47\n",
      "Validation cost: 0.412886381149292, on Epoch 48\n",
      "Validation cost: 0.40094903111457825, on Epoch 49\n",
      "Validation cost: 0.3884446918964386, on Epoch 50\n",
      "Validation cost: 0.37668442726135254, on Epoch 51\n",
      "Validation cost: 0.365875780582428, on Epoch 52\n",
      "Validation cost: 0.3539131283760071, on Epoch 53\n",
      "Validation cost: 0.3426079750061035, on Epoch 54\n",
      "Validation cost: 0.33137741684913635, on Epoch 55\n",
      "Validation cost: 0.3207705318927765, on Epoch 56\n",
      "Validation cost: 0.3105773329734802, on Epoch 57\n",
      "Validation cost: 0.30098575353622437, on Epoch 58\n",
      "Validation cost: 0.2912335693836212, on Epoch 59\n",
      "Validation cost: 0.2818009853363037, on Epoch 60\n",
      "Validation cost: 0.27317726612091064, on Epoch 61\n",
      "Validation cost: 0.2646191418170929, on Epoch 62\n",
      "Validation cost: 0.2575370669364929, on Epoch 63\n",
      "Validation cost: 0.24932383000850677, on Epoch 64\n",
      "Validation cost: 0.2411424070596695, on Epoch 65\n",
      "Validation cost: 0.23378442227840424, on Epoch 66\n",
      "Validation cost: 0.2271193563938141, on Epoch 67\n",
      "Validation cost: 0.2199912667274475, on Epoch 68\n",
      "Validation cost: 0.21385952830314636, on Epoch 69\n",
      "Validation cost: 0.20865732431411743, on Epoch 70\n",
      "Validation cost: 0.2029525190591812, on Epoch 71\n",
      "Validation cost: 0.19724076986312866, on Epoch 72\n",
      "Validation cost: 0.19219453632831573, on Epoch 73\n",
      "Validation cost: 0.18795375525951385, on Epoch 74\n",
      "Validation cost: 0.1831628978252411, on Epoch 75\n",
      "Validation cost: 0.17953798174858093, on Epoch 76\n",
      "Validation cost: 0.1758003830909729, on Epoch 77\n",
      "Validation cost: 0.17323772609233856, on Epoch 78\n",
      "Validation cost: 0.17002910375595093, on Epoch 79\n",
      "Validation cost: 0.1680269092321396, on Epoch 80\n",
      "Validation cost: 0.165932297706604, on Epoch 81\n",
      "Validation cost: 0.16398926079273224, on Epoch 82\n",
      "Validation cost: 0.16307432949543, on Epoch 83\n",
      "Validation cost: 0.16169056296348572, on Epoch 84\n",
      "Validation cost: 0.1631590873003006, on Epoch 85\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-70dec87cb140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mval_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m#create validation dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mval_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dict\u001b[0m \u001b[0;34m)\u001b[0m            \u001b[0;31m#compute the cost on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation cost: {}, on Epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoetsai/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoetsai/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 564\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoetsai/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 637\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/zoetsai/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zoetsai/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m--> 628\u001b[0;31m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Execute\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    tf.initialize_all_variables().run()     #initialize all variables in the model\n",
    "\n",
    "    for k in range(num_epochs):\n",
    "\n",
    "        #Generate Data for each epoch\n",
    "        #What this does is it creates a list of of elements of length seq_len, each of size [batch_size,input_size]\n",
    "        #this is required to feed data into rnn.rnn\n",
    "        tempX,y = gen_data(50,seq_len,batch_size)\n",
    "        X = []\n",
    "        for i in range(seq_len):\n",
    "            X.append(tempX[:,i,:])\n",
    "\n",
    "        #Create the dictionary of inputs to feed into sess.run\n",
    "        temp_dict = {inputs[i]:X[i] for i in range(seq_len)}\n",
    "        temp_dict.update({result: y})\n",
    "\n",
    "        sess.run(train_op,feed_dict=temp_dict)   #perform an update on the parameters\n",
    "\n",
    "        val_dict = {inputs[i]:X_val[i] for i in range(seq_len)}  #create validation dictionary\n",
    "        val_dict.update({result: y_val})\n",
    "        c_val = sess.run(cost, feed_dict = val_dict )            #compute the cost on the validation set\n",
    "        \n",
    "        print(\"Validation cost: {}, on Epoch {}\".format(c_val,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
